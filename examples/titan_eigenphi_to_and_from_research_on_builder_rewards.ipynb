{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep_utils import *\n",
    "from plot_prep_utils import *\n",
    "import pandas as pd\n",
    "\n",
    "dfe = get_eigenphi_march_blocks_with_to_and_from()\n",
    "dft = get_titan_march_blocks_with_to_and_from()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5842\n",
      "7802\n",
      "1682447\n",
      "2760243\n"
     ]
    }
   ],
   "source": [
    "print(len(dfe[\"to_address\"].unique()))\n",
    "print(len(dfe[\"from_address\"].unique()))\n",
    "print(len(dft[\"to_address\"].unique()))\n",
    "print(len(dft[\"from_address\"].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_top_rewards(df, address_type, output_file):\n",
    "    \"\"\"\n",
    "    Processes rewards data to return the top 50 addresses and optionally saves it to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing the transaction data.\n",
    "    address_type (str): 'to_address' or 'from_address' for reward aggregation.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame holding the top 50 addresses sorted by rewards.\n",
    "    \"\"\"\n",
    "    if address_type not in ['to_address', 'from_address']:\n",
    "        raise ValueError(\"address_type must be 'to_address' or 'from_address'\")\n",
    "\n",
    "    subtotal_df = df.groupby(address_type)[\"builder_reward\"].sum().reset_index()\n",
    "    subtotal_df[\"builder_reward\"] = subtotal_df[\"builder_reward\"].astype(float)\n",
    "    sorted_df = subtotal_df.sort_values(\"builder_reward\", ascending=False).head(50)\n",
    "\n",
    "    if output_file:\n",
    "        sorted_df.to_csv(output_file, index=False)\n",
    "        print(f\"DataFrame exported to {output_file}\")\n",
    "\n",
    "    return sorted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to top_50_titan_rewards_from.csv\n",
      "DataFrame exported to top_50_titan_rewards_to.csv\n",
      "DataFrame exported to top_50_eigenphi_rewards_from.csv\n",
      "DataFrame exported to top_50_eigenphi_rewards_to.csv\n"
     ]
    }
   ],
   "source": [
    "top50_subtotal_from_dft = get_top_rewards(dft, 'from_address', 'top_50_titan_rewards_from.csv')\n",
    "top50_subtotal_to_dft = get_top_rewards(dft, 'to_address', 'top_50_titan_rewards_to.csv')\n",
    "top50_subtotal_from_dfe = get_top_rewards(dfe, 'from_address', 'top_50_eigenphi_rewards_from.csv')   \n",
    "top50_subtotal_to_dfe = get_top_rewards(dfe, 'to_address', 'top_50_eigenphi_rewards_to.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common from_address between datasets:\n",
      "Common to_address between datasets:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_common_addresses(df1, df2, address_column, output_file):\n",
    "    \"\"\"\n",
    "    Finds common addresses between two datasets and saves the result to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): First dataset containing addresses.\n",
    "        df2 (pd.DataFrame): Second dataset containing addresses.\n",
    "        address_column (str): The name of the column to merge on ('from_address' or 'to_address').\n",
    "        output_file (str): The filename for the output CSV.\n",
    "    \"\"\"\n",
    "    # Merging on specified address column\n",
    "    common_addresses = pd.merge(df1, df2, on=address_column)\n",
    "    print(f\"Common {address_column} between datasets:\")\n",
    "    # print(common_addresses)\n",
    "\n",
    "    # Save to CSV\n",
    "    common_addresses.to_csv(output_file, index=False)\n",
    "    # print(f\"DataFrame exported to {output_file}\")\n",
    "\n",
    "# Assuming subtotal_from_dft, subtotal_from_dfe, subtotal_to_dft, and subtotal_to_dfe are already defined:\n",
    "\n",
    "# Find common from_addresses between EigenPhi and Titan\n",
    "find_common_addresses(top50_subtotal_from_dft, top50_subtotal_from_dfe, 'from_address', 'common_from_addresses.csv')\n",
    "\n",
    "# Find common to_addresses between EigenPhi and Titan\n",
    "find_common_addresses(top50_subtotal_to_dft, top50_subtotal_to_dfe, 'to_address', 'common_to_addresses.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find uncommon addresses between EigenPhi and Titan\n",
    "import pandas as pd\n",
    "\n",
    "def find_uncommon_addresses(df1, df2, address_column, eigenphi_output_file, titan_output_file):\n",
    "    \"\"\"\n",
    "    Finds uncommon addresses between two datasets and saves the result to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): First dataset containing addresses.\n",
    "        df2 (pd.DataFrame): Second dataset containing addresses.\n",
    "        address_column (str): The name of the column to merge on ('from_address' or 'to_address').\n",
    "        output_file (str): The filename for the output CSV.\n",
    "    \"\"\"\n",
    "    # Assuming subtotal_from_dft and subtotal_from_dfe are already defined DataFrame from previous steps:\n",
    "    # Perform an outer join merge\n",
    "    all_addresses = pd.merge(df1, df2, on=address_column, how='outer', indicator=True)\n",
    "    \n",
    "    # Filter results to get non-overlapping addresses\n",
    "    uncommon_addresses = all_addresses[all_addresses['_merge'] != 'both']\n",
    "    \n",
    "    \n",
    "    # pd.merge adds a column '_merge' that indicates from which DataFrame the rows come from:\n",
    "    # \"left_only\" for EigenPhi, \"right_only\" for Titan, and \"both\" for common.\n",
    "\n",
    "    # Optionally, split into two DataFrames depending on source\n",
    "    uncommon_eigenphi = uncommon_addresses[uncommon_addresses['_merge'] == 'left_only']\n",
    "    uncommon_titan = uncommon_addresses[uncommon_addresses['_merge'] == 'right_only']\n",
    "\n",
    "    uncommon_eigenphi[[address_column]].to_csv(eigenphi_output_file, index=False)\n",
    "    uncommon_titan[[address_column]].to_csv(titan_output_file, index=False)\n",
    "    \n",
    "    \n",
    "# Find uncommon from_addresses between EigenPhi and Titan\n",
    "find_uncommon_addresses(top50_subtotal_from_dfe, top50_subtotal_from_dft, 'from_address', 'uncommon_from_addresses_eigenphi.csv', 'uncommon_from_addresses_titan.csv')\n",
    "\n",
    "\n",
    "# Find uncommon to_addresses between EigenPhi and Titan\n",
    "find_uncommon_addresses(top50_subtotal_to_dfe, top50_subtotal_to_dft, 'to_address', 'uncommon_to_addresses_eigenphi.csv', 'uncommon_to_addresses_titan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/lxpn1ltx7t97r1v1k92vly1w0000gn/T/ipykernel_13950/1382655531.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  contract_df = contract_df.groupby(\"to_address\").apply(lambda x: x.nlargest(50, \"builder_reward\")).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "address_list = [\"0x6f1cdbbb4d53d226cf4b917bf768b94acbab6168\",\n",
    "\"0xc6fecdf760af24095cded954de7d81ab49f8bae1\",\n",
    "\"0x98c3d3183c4b8a650614ad179a1a98be0a8d6b8e\",\n",
    "\"0xfbeedcfe378866dab6abbafd8b2986f5c1768737\",\n",
    "\"0x73a8a6f5d9762ea5f1de193ec19cdf476c7e86b1\",\n",
    "\"0x0000000000a84d1a9b0063a910315c7ffa9cd248\",\n",
    "\"0x0000e0ca771e21bd00057f54a68c30d400000000\",\n",
    "\"0x24902aa0cf0000a08c0ea0b003b0c0bf600000e0\",\n",
    "\"0x53facee52e897740b140f5304e9cd9dc6238d735\",\n",
    "\"0xd4674001a9a66b31f3c09e3b1fec465404c83d35\",]\n",
    "\n",
    "contract_df = dft[dft[\"to_address\"].isin(address_list)]\n",
    "\n",
    "contract_df = contract_df.groupby(\"to_address\").apply(lambda x: x.nlargest(50, \"builder_reward\")).reset_index(drop=True)\n",
    "\n",
    "contract_df.to_csv(\"left.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
